{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjIw6aznmbpA"
      },
      "source": [
        "# Generative AI project about Data Augmentation\n",
        "> *This is the notebook for the ninth Profession AI project about Generative AI module*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKM3dG8tmbpB"
      },
      "source": [
        "## Setup & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMOFpywHmjlA",
        "outputId": "bba60265-03fe-481e-afc3-9bbe62d411af"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Silvano315/Gen-AI-for-Data-Augmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3uLuJ8iNmzUg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/Gen-AI-for-Data-Augmentation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0xsy-jYm22T",
        "outputId": "86edaabd-f04f-47e5-a061-ef6b12751b41"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D-o55hUmbpB",
        "outputId": "46596f34-af02-4d21-f324-f00586ca0130"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DJfUHw5mbpB"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD7ifruzEF-K",
        "outputId": "c3437683-1572-44d0-ac37-7a18209b98a5"
      },
      "outputs": [],
      "source": [
        "!pip install clean-fid\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install -q transformers datasets accelerate sentencepiece\n",
        "!pip install -q git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pEnqqVV6mbpB"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import json\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "from src.data.dataset import PetDatasetHandler\n",
        "from src.captioning.caption_generator import CaptionGenerator\n",
        "from src.captioning.captioning_blip_2 import BLIP2CaptionGenerator\n",
        "from src.captioning.git_caption_generator import GITCaptionGenerator\n",
        "from src.data.data_with_captions import PetDatasetWithCaptions\n",
        "from src.generation.text_generation import TextVariationGenerator\n",
        "from src.utils.logging import GANLogger\n",
        "from src.generation.image_generator import GANConfig, ConditionalGAN\n",
        "from src.training.callbacks import EarlyStopping, ModelCheckpoint, MetricsHistory\n",
        "from src.evaluation.metrics import FIDScore, CLIPScore, MetricsTracker\n",
        "from src.training.training import GANTrainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjRH_3IhmbpB"
      },
      "source": [
        "## Initialize and load dataset without transforms for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J3f0djrmbpC"
      },
      "outputs": [],
      "source": [
        "data_dir = Path('./data')\n",
        "handler = PetDatasetHandler(data_dir)\n",
        "train_dataset, test_dataset = handler.load_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqincMqImbpC"
      },
      "source": [
        "### Basic dataset information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H-4zr31mbpC",
        "outputId": "5cfa0881-f3ed-4533-b1f0-3075195783b7"
      },
      "outputs": [],
      "source": [
        "info = handler.get_dataset_info()\n",
        "print(\"Dataset Information:\")\n",
        "for key, value in info.items():\n",
        "    print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c4L9HRbmbpC"
      },
      "source": [
        "### Plot distributions and samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "h3-WAPGXmbpC",
        "outputId": "c7ef0f99-d3f1-49cf-d3c0-8d3aa1170f3d"
      },
      "outputs": [],
      "source": [
        "handler.plot_class_distribution().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "tyIYd0_SmbpC",
        "outputId": "375e165a-4979-47a7-e058-15a2b638669e"
      },
      "outputs": [],
      "source": [
        "handler.visualize_samples(9).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZTMNAxHmbpC"
      },
      "source": [
        "### Get detailed image statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH1C4c-0mbpC",
        "outputId": "ab263331-d840-44f9-ae6f-72c3159e4c34"
      },
      "outputs": [],
      "source": [
        "stats = handler.get_image_stats(sample_size=100)\n",
        "print(\"\\nImage Statistics:\")\n",
        "for category, values in stats.items():\n",
        "    print(f\"\\n{category.upper()}:\")\n",
        "    for key, value in values.items():\n",
        "        print(f\"{key}: {value:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ToX6RAmbpD"
      },
      "source": [
        "### For training, load with transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP1GeQZYmbpD"
      },
      "outputs": [],
      "source": [
        "train_transforms = handler.get_training_transforms()\n",
        "train_dataset, test_dataset = handler.load_dataset(transform=train_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ha6Oe9S4hkK"
      },
      "source": [
        "## Image Captioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare caption generators: \n",
        "1. **Blip**\n",
        "2. **Blip-2**\n",
        "3. **GIT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurations\n",
        "\n",
        "def get_random_images(image_dir, count=5):\n",
        "    \"\"\"Randomly select images from the dataset.\"\"\"\n",
        "    image_paths = list(Path(image_dir).glob(\"*.jpg\"))\n",
        "    return random.sample(image_paths, min(count, len(image_paths)))\n",
        "\n",
        "data_dir = Path('./data')\n",
        "handler = PetDatasetHandler(data_dir)\n",
        "train_dataset, test_dataset = handler.load_dataset()\n",
        "\n",
        "image_dir = \"data/oxford-iiit-pet/images\"\n",
        "sample_images = get_random_images(image_dir, count=10)\n",
        "print(f\"Selected {len(sample_images)} random images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test BLIP original model\n",
        "\n",
        "print(\"Test di BLIP...\")\n",
        "blip_model = CaptionGenerator()\n",
        "blip_captions = {}\n",
        "\n",
        "for img_path in sample_images:\n",
        "    caption = blip_model.generate_caption(str(img_path))\n",
        "    blip_captions[str(img_path)] = caption\n",
        "    print(f\"BLIP - {img_path.name}: {caption}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test BLIP-2 model \n",
        "# Be Carefull !! Blip-2 is high consuming and high memory requiring, run this cell if you have high computational resources.\n",
        "\n",
        "print(\"\\nTest di BLIP-2...\")\n",
        "blip2_model = BLIP2CaptionGenerator(model_name=\"Salesforce/blip2-opt-2.7b\")\n",
        "blip2_captions = {}\n",
        "\n",
        "for img_path in sample_images:\n",
        "    caption = blip2_model.generate_caption(str(img_path))\n",
        "    blip2_captions[str(img_path)] = caption\n",
        "    print(f\"BLIP-2 - {img_path.name}: {caption}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test GIT model\n",
        "\n",
        "print(\"\\nTest di GIT...\")\n",
        "git_model_name = \"microsoft/git-base-coco\"\n",
        "processor_git = AutoProcessor.from_pretrained(git_model_name)\n",
        "model_git = AutoModelForCausalLM.from_pretrained(git_model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_git = model_git.to(device)\n",
        "\n",
        "git_captions = {}\n",
        "\n",
        "for img_path in sample_images:\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    inputs_git = processor_git(images=image, return_tensors=\"pt\").to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        generated_ids = model_git.generate(\n",
        "            pixel_values=inputs_git.pixel_values,\n",
        "            max_length=50,\n",
        "            num_beams=5\n",
        "        )\n",
        "    \n",
        "    caption = processor_git.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    git_captions[str(img_path)] = caption\n",
        "    print(f\"GIT - {img_path.name}: {caption}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize images with captions from three models (side by side)\n",
        "\n",
        "from textwrap import wrap\n",
        "\n",
        "def visualize_comparison(image_paths, blip_captions, blip2_captions, git_captions, wrap_width=30):\n",
        "    \"\"\"Visualizza il confronto tra le caption generate dai diversi modelli.\"\"\"\n",
        "    n_images = len(image_paths)\n",
        "    \n",
        "    fig, axes = plt.subplots(n_images, 3, figsize=(15, 5 * n_images))\n",
        "    \n",
        "    if n_images > 0:\n",
        "        axes[0, 0].set_title(\"BLIP\", fontsize=14)\n",
        "        axes[0, 1].set_title(\"BLIP-2\", fontsize=14)\n",
        "        axes[0, 2].set_title(\"GIT\", fontsize=14)\n",
        "    \n",
        "    for idx, img_path in enumerate(image_paths):\n",
        "        img_path_str = str(img_path)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        \n",
        "        # BLIP\n",
        "        axes[idx, 0].imshow(img)\n",
        "        axes[idx, 0].axis('off')\n",
        "        wrapped_caption = \"\\n\".join(wrap(blip_captions[img_path_str], wrap_width))\n",
        "        axes[idx][0].set_xlabel(wrapped_caption, fontsize = 12)\n",
        "\n",
        "        # BLIP-2\n",
        "        axes[idx][1].imshow(img)\n",
        "        axes[idx][1].axis('off')\n",
        "        wrapped_caption = \"\\n\".join(wrap(blip2_captions[img_path_str], wrap_width))\n",
        "        axes[idx][1].set_xlabel(wrapped_caption, fontsize=12)\n",
        "        \n",
        "        # GIT\n",
        "        axes[idx][2].imshow(img)\n",
        "        axes[idx][2].axis('off')\n",
        "        wrapped_caption = \"\\n\".join(wrap(git_captions[img_path_str], wrap_width))\n",
        "        axes[idx][2].set_xlabel(wrapped_caption, fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_comparison(sample_images, blip_captions, blip2_captions, git_captions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADVSzXMi4hkK"
      },
      "source": [
        "### Initialize caption generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI2hQG804hkK"
      },
      "outputs": [],
      "source": [
        "caption_gen = GITCaptionGenerator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Dataset (If you havenâ€™t done it before)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = Path('./data')\n",
        "handler = PetDatasetHandler(data_dir)\n",
        "train_dataset, test_dataset = handler.load_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "615M0HNu4hkK"
      },
      "source": [
        "### Test single image caption generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzvz7bLQ4hkL",
        "outputId": "fd6e472c-c753-4531-96fc-d9124db20eba"
      },
      "outputs": [],
      "source": [
        "sample = random.randint(0, len(train_dataset)-1)\n",
        "sample_image_path = Path(train_dataset._images[sample])\n",
        "label = train_dataset.classes[train_dataset[sample][1]]\n",
        "caption = caption_gen.generate_caption(sample_image_path, label, max_length = 50)\n",
        "print(f\"Sample caption: {caption}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "6xGBj8fN6sbt",
        "outputId": "877d3a6f-0012-48ec-f50f-06c8b8f8949d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.title(f\"{label}\")\n",
        "fig = plt.imshow(train_dataset[sample][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-N0xVkY4hkL"
      },
      "source": [
        "### Process a batch of images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1acVgcv4hkL",
        "outputId": "0d72b62d-bfbc-4b90-f06e-c743355bf315"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "image_paths = [Path(img) for img in train_dataset._images[:10]]\n",
        "labels = [train_dataset.classes[train_dataset[i][1]] for i in range(10)]\n",
        "captions = caption_gen.process_batch(image_paths, labels, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx7KTRb7Fm4d"
      },
      "source": [
        "### Process train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8p7xWxRFs7l"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "image_paths = [Path(img) for img in test_dataset._images]\n",
        "labels = [test_dataset.classes[test_dataset[i][1]] for i in range(len(image_paths))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVymaIVQGJrc",
        "outputId": "32f3af2c-4ee7-43e9-c38c-73c70f306fcb"
      },
      "outputs": [],
      "source": [
        "captions = caption_gen.process_batch(image_paths, labels, batch_size=batch_size)\n",
        "\n",
        "caption_gen.save_captions(save_dir / 'captions_testdataset.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsewHEa84hkL"
      },
      "source": [
        "### Save & Load captions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqkoWAjQ4hkL"
      },
      "outputs": [],
      "source": [
        "save_dir = Path('/content/drive/MyDrive/outputs_master_ProfAI/captions')\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "caption_gen.save_captions(save_dir / 'captions_testdataset.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVdAoWbg4hkL"
      },
      "outputs": [],
      "source": [
        "caption_gen.load_captions(save_dir / 'captions.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-7Q6Z3B4hkL"
      },
      "source": [
        "### Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "OgmEGDzT4hkL",
        "outputId": "a203537e-48da-4269-b333-de33a2dcf9cd"
      },
      "outputs": [],
      "source": [
        "caption_gen.visualize_captions(num_samples=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb-GAogK4hkM"
      },
      "source": [
        "### Print some statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOjJeugs4hkM",
        "outputId": "71a32e59-99b5-49fe-8b97-352a8d0c3a4a"
      },
      "outputs": [],
      "source": [
        "print(f\"\\nTotal captions generated: {len(caption_gen.captions_cache)}\")\n",
        "print(\"\\nSample of generated captions:\")\n",
        "for path, caption in list(caption_gen.captions_cache.items())[:3]:\n",
        "    print(f\"\\nImage: {Path(path).name}\")\n",
        "    print(f\"Caption: {caption}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Generations with Flan-T5 to increase numbers of captions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initialize Text Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generator = TextVariationGenerator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### How it works\n",
        "> Comparison of different types of prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard generation\n",
        "\n",
        "original_caption = \"A gray cat sitting on a window sill - This is a British Shorthair.\"\n",
        "\n",
        "standard_variations = generator.generate_variations(\n",
        "    original_caption,\n",
        "    num_variations=3,\n",
        "    prompt_type=\"standard\",\n",
        "    temperature=0.8\n",
        ")\n",
        "print(\"Standard Prompting:\", standard_variations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generation with a specific prompt\n",
        "\n",
        "specific_variations = generator.generate_variations(\n",
        "    original_caption,\n",
        "    num_variations=3,\n",
        "    prompt_type=\"specific\",\n",
        "    temperature=0.8\n",
        ")\n",
        "print(\"Specific Prompting:\", specific_variations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generation with few-shot prompting\n",
        "\n",
        "fewshot_variations = generator.generate_variations(\n",
        "    original_caption,\n",
        "    num_variations=3,\n",
        "    prompt_type=\"few-shot\",\n",
        "    temperature=0.8\n",
        ")\n",
        "print(\"Few-Shot Prompting:\", fewshot_variations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUUthrS4Ac3h"
      },
      "source": [
        "## Imgae Generation with Conditional GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY6xFDKYAc3h",
        "outputId": "e247399b-4a59-4963-da0e-3a8002639797"
      },
      "outputs": [],
      "source": [
        "# Setup device\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device used: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WzBPGaG_Ac3i"
      },
      "outputs": [],
      "source": [
        "# Configurations\n",
        "\n",
        "batch_size = 32\n",
        "image_size = 128\n",
        "num_workers = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnPm2yGnAc3i",
        "outputId": "cc737556-9022-4c98-8f2e-81a1d8fb4a5c"
      },
      "outputs": [],
      "source": [
        "# Setup components\n",
        "\n",
        "output_dir = Path(\"/content/drive/MyDrive/outputs_master_ProfAI\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "checkpoint_dir = output_dir / \"checkpoints\"\n",
        "log_dir = output_dir / \"logs\"\n",
        "\n",
        "metrics = MetricsTracker([\n",
        "    FIDScore(device=device),\n",
        "    CLIPScore(device=device)\n",
        "])\n",
        "\n",
        "logger = GANLogger(\"conditional_gan\", log_dir=log_dir)\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='fid', patience=5),\n",
        "    ModelCheckpoint(filepath=checkpoint_dir / \"best_model.pt\", monitor='fid'),\n",
        "    MetricsHistory(log_dir=log_dir / \"metrics\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "I0yjVD0295yM"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "\n",
        "data_dir = Path('./data')\n",
        "handler = PetDatasetHandler(data_dir)\n",
        "train_dataset, test_dataset = handler.load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "r6mtOOHp95yN"
      },
      "outputs": [],
      "source": [
        "# Load Captions\n",
        "with open('output/captions/captions_traindataset.json', 'r') as f:\n",
        "    caption_dict = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TRoTLwvp95yN"
      },
      "outputs": [],
      "source": [
        "train_images_paths = [str(img) for img in train_dataset._images]\n",
        "\n",
        "test_images_paths = [str(img) for img in test_dataset._images]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thgLwkV0Ac3j",
        "outputId": "09f6f851-4fe2-4e56-9030-b8d027e9ad8b"
      },
      "outputs": [],
      "source": [
        "# Initialize train and val loader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "full_train_ds = PetDatasetWithCaptions(\n",
        "    image_paths=train_images_paths,\n",
        "    caption_dict=caption_dict,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_size = int(0.9 * len(full_train_ds))\n",
        "val_size = len(full_train_ds) - train_size\n",
        "train_ds, val_ds = random_split(full_train_ds, [train_size, val_size],\n",
        "                                generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "test_ds = PetDatasetWithCaptions(\n",
        "    image_paths=test_images_paths,\n",
        "    caption_dict=caption_dict,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PId4e9AMAc3k",
        "outputId": "6a9eb72d-3518-4cf8-fb2e-29d4fb3a7977"
      },
      "outputs": [],
      "source": [
        "# Initialize GAN model\n",
        "\n",
        "config = GANConfig(\n",
        "    latent_dim = 100,\n",
        "    caption_dim = 768,\n",
        "    image_size = image_size,\n",
        "    num_channels = 3,\n",
        "    generator_features = 64\n",
        ")\n",
        "\n",
        "gan = ConditionalGAN(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eJwz9DZ-Ac3k"
      },
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "\n",
        "trainer = GANTrainer(\n",
        "    gan=gan,\n",
        "    train_dataloader=train_loader,\n",
        "    val_dataloader=val_loader,\n",
        "    metrics_tracker=metrics,\n",
        "    logger=logger,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlyZmIyNAc3k",
        "outputId": "04f48ba7-5b95-4f12-8986-48c8929877c2"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "\n",
        "trainer.train(\n",
        "    num_epochs=100,\n",
        "    eval_freq=1,\n",
        "    sample_freq=500,\n",
        "    sample_dir=Path(\"samples\")\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
